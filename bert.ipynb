{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, BertTokenizerFast,AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import date, datetime, time\n",
    "from babel.dates import format_time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"diffQ_Suffix.csv\"\n",
    "save_pt='saved_weights.pt'\n",
    "device_name='cuda'\n",
    "learning_rate=1e-5\n",
    "batch_size=32\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "True     0.58898\n",
       "False    0.41102\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset)\n",
    "df.head()\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']=df['label'].map(lambda x:0 if x==True else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "67909    1\n",
       "67910    1\n",
       "67911    1\n",
       "67912    1\n",
       "67913    1\n",
       "Name: label, Length: 67914, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['prompt'], df['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zihui\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        \n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      \n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "      \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zihui\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(),lr = learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.84891071 1.21651569]\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes =np.unique(train_labels), y=train_labels)\n",
    "\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(i):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    loop=tqdm(enumerate(train_dataloader),total=len(train_dataloader),leave=True)\n",
    "    for step,batch in loop:\n",
    "        \n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    " \n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "        loop.set_description(f'Epoch [{i}/{epochs+1}]')\n",
    "        loop.set_postfix(loss = loss)\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "      # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    \n",
    "    print(\"\\nEvaluating...\")\n",
    "  \n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    loop1=tqdm(enumerate(val_dataloader),total=len(val_dataloader),leave=True)\n",
    "    for step,batch in loop1:\n",
    "        \n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "          # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "        \n",
    "        loop1.set_postfix(loss = loss)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [0/11]: 100%|██████████| 1486/1486 [01:26<00:00, 17.25it/s, loss=tensor(0.2618, device='cuda:0', grad_fn=<NllLossBackward0>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 52/319 [00:02<00:13, 19.41it/s, loss=tensor(0.1360, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    50  of    319.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 103/319 [00:05<00:10, 19.87it/s, loss=tensor(0.1089, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    319.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 153/319 [00:08<00:08, 19.79it/s, loss=tensor(0.1156, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   150  of    319.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 203/319 [00:10<00:05, 19.40it/s, loss=tensor(0.1163, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   200  of    319.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 253/319 [00:13<00:03, 19.68it/s, loss=tensor(0.1178, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   250  of    319.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 302/319 [00:15<00:00, 19.75it/s, loss=tensor(0.1380, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   300  of    319.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:16<00:00, 19.25it/s, loss=tensor(0.1071, device='cuda:0')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.343\n",
      "Validation Loss: 0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/11]:  13%|█▎        | 197/1486 [00:11<01:13, 17.55it/s, loss=tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward0>)]"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs): \n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train(epoch)\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#load weights of best model\n",
    "path = save_pt\n",
    "model.load_state_dict(torch.load(path))\n",
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
